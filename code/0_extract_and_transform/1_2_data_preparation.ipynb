{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Flow Analysis and Anomaly Detection Script\n",
    "# This script processes PCAP files to extract, analyze and detect network flow anomalies\n",
    "# It implements feature engineering for network security analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os  # For interacting with the file system\n",
    "import pandas as pd  # For handling dataframes and CSVs\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "from scapy import all\n",
    "from nfstream import NFStreamer  # For working with PCAP files and flow analysis\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting network flow analysis and anomaly detection process...\n",
      "Looking for PCAP files in directory: pcap_files\n",
      "Processing file: pcap_files\\trace_a_1.pcap\n",
      "Found 23019 flows in trace_a_1.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_1.pcap: 100%|██████████| 23019/23019 [00:09<00:00, 2531.41flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_10.pcap\n",
      "Found 21963 flows in trace_a_10.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_10.pcap: 100%|██████████| 21963/21963 [00:09<00:00, 2370.76flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_11.pcap\n",
      "Found 18030 flows in trace_a_11.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_11.pcap: 100%|██████████| 18030/18030 [00:08<00:00, 2066.67flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_12.pcap\n",
      "Found 19826 flows in trace_a_12.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_12.pcap: 100%|██████████| 19826/19826 [00:08<00:00, 2233.05flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_13.pcap\n",
      "Found 17582 flows in trace_a_13.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_13.pcap: 100%|██████████| 17582/17582 [00:08<00:00, 2155.04flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_14.pcap\n",
      "Found 18516 flows in trace_a_14.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_14.pcap: 100%|██████████| 18516/18516 [00:08<00:00, 2226.86flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_15.pcap\n",
      "Found 21081 flows in trace_a_15.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_15.pcap: 100%|██████████| 21081/21081 [00:08<00:00, 2453.51flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_16.pcap\n",
      "Found 20535 flows in trace_a_16.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_16.pcap: 100%|██████████| 20535/20535 [00:09<00:00, 2229.78flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_17.pcap\n",
      "Found 20082 flows in trace_a_17.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_17.pcap: 100%|██████████| 20082/20082 [00:08<00:00, 2327.55flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_18.pcap\n",
      "Found 19273 flows in trace_a_18.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_18.pcap: 100%|██████████| 19273/19273 [00:08<00:00, 2369.48flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_19.pcap\n",
      "Found 17677 flows in trace_a_19.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_19.pcap: 100%|██████████| 17677/17677 [00:08<00:00, 2057.37flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_2.pcap\n",
      "Found 16798 flows in trace_a_2.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_2.pcap: 100%|██████████| 16798/16798 [00:07<00:00, 2131.71flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_20.pcap\n",
      "Found 20510 flows in trace_a_20.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_20.pcap: 100%|██████████| 20510/20510 [00:08<00:00, 2351.34flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_21.pcap\n",
      "Found 17665 flows in trace_a_21.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_21.pcap: 100%|██████████| 17665/17665 [00:08<00:00, 2062.72flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_22.pcap\n",
      "Found 18072 flows in trace_a_22.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_22.pcap: 100%|██████████| 18072/18072 [00:07<00:00, 2298.56flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_23.pcap\n",
      "Found 18576 flows in trace_a_23.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_23.pcap: 100%|██████████| 18576/18576 [00:08<00:00, 2090.48flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_24.pcap\n",
      "Found 20074 flows in trace_a_24.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_24.pcap: 100%|██████████| 20074/20074 [00:08<00:00, 2331.91flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_25.pcap\n",
      "Found 20802 flows in trace_a_25.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_25.pcap: 100%|██████████| 20802/20802 [00:08<00:00, 2431.02flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_26.pcap\n",
      "Found 20633 flows in trace_a_26.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_26.pcap: 100%|██████████| 20633/20633 [00:08<00:00, 2329.22flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_27.pcap\n",
      "Found 17501 flows in trace_a_27.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_27.pcap: 100%|██████████| 17501/17501 [00:08<00:00, 2085.60flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_28.pcap\n",
      "Found 18294 flows in trace_a_28.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_28.pcap: 100%|██████████| 18294/18294 [00:08<00:00, 2176.39flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_29.pcap\n",
      "Found 18727 flows in trace_a_29.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_29.pcap: 100%|██████████| 18727/18727 [00:08<00:00, 2205.66flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_3.pcap\n",
      "Found 18430 flows in trace_a_3.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_3.pcap: 100%|██████████| 18430/18430 [00:08<00:00, 2275.39flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_30.pcap\n",
      "Found 19023 flows in trace_a_30.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_30.pcap: 100%|██████████| 19023/19023 [00:08<00:00, 2134.05flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_31.pcap\n",
      "Found 24345 flows in trace_a_31.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_31.pcap: 100%|██████████| 24345/24345 [00:08<00:00, 2850.56flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_32.pcap\n",
      "Found 17665 flows in trace_a_32.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_32.pcap: 100%|██████████| 17665/17665 [00:08<00:00, 2107.87flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_33.pcap\n",
      "Found 17960 flows in trace_a_33.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_33.pcap: 100%|██████████| 17960/17960 [00:08<00:00, 2119.10flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_34.pcap\n",
      "Found 18563 flows in trace_a_34.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_34.pcap: 100%|██████████| 18563/18563 [00:08<00:00, 2246.73flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_35.pcap\n",
      "Found 16779 flows in trace_a_35.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_35.pcap: 100%|██████████| 16779/16779 [00:08<00:00, 2009.32flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_36.pcap\n",
      "Found 22591 flows in trace_a_36.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_36.pcap: 100%|██████████| 22591/22591 [00:08<00:00, 2647.54flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_37.pcap\n",
      "Found 21634 flows in trace_a_37.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_37.pcap: 100%|██████████| 21634/21634 [00:08<00:00, 2683.79flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_38.pcap\n",
      "Found 20679 flows in trace_a_38.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_38.pcap: 100%|██████████| 20679/20679 [00:08<00:00, 2483.85flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_39.pcap\n",
      "Found 19001 flows in trace_a_39.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_39.pcap: 100%|██████████| 19001/19001 [00:07<00:00, 2395.98flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_4.pcap\n",
      "Found 18902 flows in trace_a_4.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_4.pcap: 100%|██████████| 18902/18902 [00:07<00:00, 2509.09flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_40.pcap\n",
      "Found 20941 flows in trace_a_40.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_40.pcap: 100%|██████████| 20941/20941 [00:08<00:00, 2565.50flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_41.pcap\n",
      "Found 27382 flows in trace_a_41.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_41.pcap: 100%|██████████| 27382/27382 [00:09<00:00, 3020.53flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_42.pcap\n",
      "Found 18396 flows in trace_a_42.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_42.pcap: 100%|██████████| 18396/18396 [00:07<00:00, 2305.97flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_43.pcap\n",
      "Found 16281 flows in trace_a_43.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_43.pcap: 100%|██████████| 16281/16281 [00:07<00:00, 2136.51flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_44.pcap\n",
      "Found 17909 flows in trace_a_44.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_44.pcap: 100%|██████████| 17909/17909 [00:07<00:00, 2241.55flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_45.pcap\n",
      "Found 19257 flows in trace_a_45.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_45.pcap: 100%|██████████| 19257/19257 [00:08<00:00, 2279.10flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_46.pcap\n",
      "Found 18156 flows in trace_a_46.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_46.pcap: 100%|██████████| 18156/18156 [00:08<00:00, 2267.40flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_47.pcap\n",
      "Found 19268 flows in trace_a_47.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_47.pcap: 100%|██████████| 19268/19268 [00:08<00:00, 2259.33flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_48.pcap\n",
      "Found 21783 flows in trace_a_48.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_48.pcap: 100%|██████████| 21783/21783 [00:08<00:00, 2682.75flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_49.pcap\n",
      "Found 21207 flows in trace_a_49.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_49.pcap: 100%|██████████| 21207/21207 [00:08<00:00, 2632.49flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_5.pcap\n",
      "Found 20015 flows in trace_a_5.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_5.pcap: 100%|██████████| 20015/20015 [00:07<00:00, 2521.97flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_50.pcap\n",
      "Found 21986 flows in trace_a_50.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_50.pcap: 100%|██████████| 21986/21986 [00:08<00:00, 2523.98flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_51.pcap\n",
      "Found 18619 flows in trace_a_51.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_51.pcap: 100%|██████████| 18619/18619 [00:08<00:00, 2205.42flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_52.pcap\n",
      "Found 17665 flows in trace_a_52.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_52.pcap: 100%|██████████| 17665/17665 [00:08<00:00, 2033.66flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_53.pcap\n",
      "Found 13030 flows in trace_a_53.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_53.pcap: 100%|██████████| 13030/13030 [00:05<00:00, 2204.85flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_6.pcap\n",
      "Found 18724 flows in trace_a_6.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_6.pcap: 100%|██████████| 18724/18724 [00:07<00:00, 2369.70flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_7.pcap\n",
      "Found 21135 flows in trace_a_7.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_7.pcap: 100%|██████████| 21135/21135 [00:08<00:00, 2430.04flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_8.pcap\n",
      "Found 18742 flows in trace_a_8.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_8.pcap: 100%|██████████| 18742/18742 [00:08<00:00, 2251.27flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: pcap_files\\trace_a_9.pcap\n",
      "Found 18143 flows in trace_a_9.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting flows from trace_a_9.pcap: 100%|██████████| 18143/18143 [00:08<00:00, 2218.07flows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow extraction completed. Creating DataFrame...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting network flow analysis and anomaly detection process...\")\n",
    "\n",
    "# Specify the directory containing the .pcap files\n",
    "pcap_directory = 'pcap_files'\n",
    "print(f\"Looking for PCAP files in directory: {pcap_directory}\")\n",
    "\n",
    "# Initialize an empty list to store all flows data\n",
    "all_flows_data = []\n",
    "\n",
    "# Iterate through each .pcap file in the directory\n",
    "for file in os.listdir(pcap_directory):\n",
    "    # Check if the file is a .pcap file\n",
    "    if file.endswith('.pcap'):\n",
    "        full_path = os.path.join(pcap_directory, file)  # Get the full path of the file\n",
    "        print(f\"Processing file: {full_path}\")\n",
    "\n",
    "        # Create an NFStreamer instance with statistical analysis enabled\n",
    "        # Set timeouts to handle both short and long-lived flows\n",
    "        my_streamer = NFStreamer(\n",
    "            source=full_path,\n",
    "            statistical_analysis=True,\n",
    "            idle_timeout=60,  # 60 seconds idle timeout\n",
    "            active_timeout=120  # 120 seconds active timeout\n",
    "        )\n",
    "\n",
    "        # List to store extracted flow data for this file\n",
    "        file_flows_data = []\n",
    "        total_flows = len(list(my_streamer))  # Count total flows for tqdm\n",
    "        my_streamer = NFStreamer(source=full_path, statistical_analysis=True,\n",
    "                                 idle_timeout=60, active_timeout=120)  # Re-create the streamer\n",
    "\n",
    "        print(f\"Found {total_flows} flows in {file}\")\n",
    "\n",
    "        # Using tqdm to track progress for flow extraction\n",
    "        with tqdm(total=total_flows, desc=f\"Extracting flows from {file}\", unit=\"flows\") as pbar:\n",
    "            for flow in my_streamer:\n",
    "                # Extract comprehensive flow metrics including statistical features\n",
    "                flow_data = {\n",
    "                    'src_ip': flow.src_ip,\n",
    "                    'dst_ip': flow.dst_ip,\n",
    "                    'src_port': flow.src_port,\n",
    "                    'dst_port': flow.dst_port,\n",
    "                    'protocol': flow.protocol,\n",
    "                    'application_name': flow.application_name,\n",
    "                    'bidirectional_packets': flow.bidirectional_packets,\n",
    "                    'bidirectional_bytes': flow.bidirectional_bytes,\n",
    "                    'bidirectional_first_seen_ms': flow.bidirectional_first_seen_ms,\n",
    "                    'bidirectional_last_seen_ms': flow.bidirectional_last_seen_ms,\n",
    "\n",
    "                    # Statistical features for anomaly detection\n",
    "                    'bidirectional_mean_ps': flow.bidirectional_mean_ps,  # Packet size statistics\n",
    "                    'bidirectional_stddev_ps': flow.bidirectional_stddev_ps,\n",
    "                    'src2dst_mean_ps': flow.src2dst_mean_ps,\n",
    "                    'src2dst_stddev_ps': flow.src2dst_stddev_ps,\n",
    "                    'dst2src_mean_ps': flow.dst2src_mean_ps,\n",
    "                    'dst2src_stddev_ps': flow.dst2src_stddev_ps,\n",
    "\n",
    "                    # Packet Inter-Arrival Time (PIAT) statistics\n",
    "                    'bidirectional_mean_piat_ms': flow.bidirectional_mean_piat_ms,\n",
    "                    'bidirectional_stddev_piat_ms': flow.bidirectional_stddev_piat_ms,\n",
    "                    'src2dst_mean_piat_ms': flow.src2dst_mean_piat_ms,\n",
    "                    'src2dst_stddev_piat_ms': flow.src2dst_stddev_piat_ms,\n",
    "                    'dst2src_mean_piat_ms': flow.dst2src_mean_piat_ms,\n",
    "                    'dst2src_stddev_piat_ms': flow.dst2src_stddev_piat_ms\n",
    "                }\n",
    "                file_flows_data.append(flow_data)\n",
    "                pbar.update(1)  # Update progress bar\n",
    "\n",
    "        # Append the current file's data to the all_flows_data list\n",
    "        all_flows_data.extend(file_flows_data)\n",
    "\n",
    "print(\"Flow extraction completed. Creating DataFrame...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created with the following structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1029447 entries, 0 to 1029446\n",
      "Data columns (total 22 columns):\n",
      " #   Column                        Non-Null Count    Dtype  \n",
      "---  ------                        --------------    -----  \n",
      " 0   src_ip                        1029447 non-null  object \n",
      " 1   dst_ip                        1029447 non-null  object \n",
      " 2   src_port                      1029447 non-null  int64  \n",
      " 3   dst_port                      1029447 non-null  int64  \n",
      " 4   protocol                      1029447 non-null  int64  \n",
      " 5   application_name              1029447 non-null  object \n",
      " 6   bidirectional_packets         1029447 non-null  int64  \n",
      " 7   bidirectional_bytes           1029447 non-null  int64  \n",
      " 8   bidirectional_first_seen_ms   1029447 non-null  int64  \n",
      " 9   bidirectional_last_seen_ms    1029447 non-null  int64  \n",
      " 10  bidirectional_mean_ps         1029447 non-null  float64\n",
      " 11  bidirectional_stddev_ps       1029447 non-null  float64\n",
      " 12  src2dst_mean_ps               1029447 non-null  float64\n",
      " 13  src2dst_stddev_ps             1029447 non-null  float64\n",
      " 14  dst2src_mean_ps               1029447 non-null  float64\n",
      " 15  dst2src_stddev_ps             1029447 non-null  float64\n",
      " 16  bidirectional_mean_piat_ms    1029447 non-null  float64\n",
      " 17  bidirectional_stddev_piat_ms  1029447 non-null  float64\n",
      " 18  src2dst_mean_piat_ms          1029447 non-null  float64\n",
      " 19  src2dst_stddev_piat_ms        1029447 non-null  float64\n",
      " 20  dst2src_mean_piat_ms          1029447 non-null  float64\n",
      " 21  dst2src_stddev_piat_ms        1029447 non-null  float64\n",
      "dtypes: float64(12), int64(7), object(3)\n",
      "memory usage: 172.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of flow data into a pandas DataFrame\n",
    "flows_df = pd.DataFrame(all_flows_data)\n",
    "\n",
    "# Display the DataFrame's summary\n",
    "print(\"DataFrame created with the following structure:\")\n",
    "print(flows_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw flows DataFrame saved to csv_files/raw_flows.csv\n"
     ]
    }
   ],
   "source": [
    "# Save raw flows to CSV\n",
    "output_path = \"csv_files/raw_flows.csv\"\n",
    "flows_df.to_csv(output_path, index=False)\n",
    "print(f\"Raw flows DataFrame saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating network features using 10 second time window...\n",
      "Calculating fan-in/fan-out metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating fan metrics: 100%|██████████| 1029447/1029447 [54:58<00:00, 312.13flows/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>application_name</th>\n",
       "      <th>bidirectional_packets</th>\n",
       "      <th>bidirectional_bytes</th>\n",
       "      <th>bidirectional_first_seen_ms</th>\n",
       "      <th>bidirectional_last_seen_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>bidirectional_mean_piat_ms</th>\n",
       "      <th>bidirectional_stddev_piat_ms</th>\n",
       "      <th>src2dst_mean_piat_ms</th>\n",
       "      <th>src2dst_stddev_piat_ms</th>\n",
       "      <th>dst2src_mean_piat_ms</th>\n",
       "      <th>dst2src_stddev_piat_ms</th>\n",
       "      <th>fan_out_src</th>\n",
       "      <th>fan_in_dst</th>\n",
       "      <th>fan_in_src</th>\n",
       "      <th>fan_out_dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>3593</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>DNS</td>\n",
       "      <td>4</td>\n",
       "      <td>360</td>\n",
       "      <td>1421927414035</td>\n",
       "      <td>1421927414036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>33661</td>\n",
       "      <td>1024</td>\n",
       "      <td>17</td>\n",
       "      <td>NFS</td>\n",
       "      <td>8</td>\n",
       "      <td>960</td>\n",
       "      <td>1421927414236</td>\n",
       "      <td>1421927414272</td>\n",
       "      <td>...</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>6.890297</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.124356</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>12.701706</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.16</td>\n",
       "      <td>13284</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>20</td>\n",
       "      <td>1950</td>\n",
       "      <td>1421927413887</td>\n",
       "      <td>1421927416277</td>\n",
       "      <td>...</td>\n",
       "      <td>125.789474</td>\n",
       "      <td>487.795105</td>\n",
       "      <td>183.538462</td>\n",
       "      <td>587.939001</td>\n",
       "      <td>474.200000</td>\n",
       "      <td>1053.091259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.6</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>1464</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>DNS</td>\n",
       "      <td>4</td>\n",
       "      <td>388</td>\n",
       "      <td>1421927414121</td>\n",
       "      <td>1421927414122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>32119</td>\n",
       "      <td>111</td>\n",
       "      <td>17</td>\n",
       "      <td>NFS</td>\n",
       "      <td>8</td>\n",
       "      <td>1008</td>\n",
       "      <td>1421927414221</td>\n",
       "      <td>1421927414299</td>\n",
       "      <td>...</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>21.388693</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>36.373067</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>42.146570</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         src_ip          dst_ip  src_port  dst_port  protocol  \\\n",
       "0    59.166.0.5   149.171.126.5      3593        53        17   \n",
       "1    59.166.0.0   149.171.126.9     33661      1024        17   \n",
       "2  175.45.176.0  149.171.126.16     13284        80         6   \n",
       "3    59.166.0.6   149.171.126.7      1464        53        17   \n",
       "4    59.166.0.0   149.171.126.9     32119       111        17   \n",
       "\n",
       "  application_name  bidirectional_packets  bidirectional_bytes  \\\n",
       "0              DNS                      4                  360   \n",
       "1              NFS                      8                  960   \n",
       "2             HTTP                     20                 1950   \n",
       "3              DNS                      4                  388   \n",
       "4              NFS                      8                 1008   \n",
       "\n",
       "   bidirectional_first_seen_ms  bidirectional_last_seen_ms  ...  \\\n",
       "0                1421927414035               1421927414036  ...   \n",
       "1                1421927414236               1421927414272  ...   \n",
       "2                1421927413887               1421927416277  ...   \n",
       "3                1421927414121               1421927414122  ...   \n",
       "4                1421927414221               1421927414299  ...   \n",
       "\n",
       "   bidirectional_mean_piat_ms  bidirectional_stddev_piat_ms  \\\n",
       "0                    0.333333                      0.577350   \n",
       "1                    5.142857                      6.890297   \n",
       "2                  125.789474                    487.795105   \n",
       "3                    0.333333                      0.577350   \n",
       "4                   11.142857                     21.388693   \n",
       "\n",
       "   src2dst_mean_piat_ms  src2dst_stddev_piat_ms  dst2src_mean_piat_ms  \\\n",
       "0              0.000000                0.000000              0.000000   \n",
       "1              7.000000               12.124356              7.333333   \n",
       "2            183.538462              587.939001            474.200000   \n",
       "3              0.000000                0.000000              0.000000   \n",
       "4             21.000000               36.373067             24.333333   \n",
       "\n",
       "   dst2src_stddev_piat_ms  fan_out_src  fan_in_dst  fan_in_src  fan_out_dst  \n",
       "0                0.000000            6           7           0            0  \n",
       "1               12.701706            7           8           0            0  \n",
       "2             1053.091259            2           2           0            0  \n",
       "3                0.000000            7           3           0            0  \n",
       "4               42.146570            7           8           0            0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the time window T in milliseconds (used for fan-in/fan-out calculation)\n",
    "T = 10  # 10 seconds window\n",
    "print(f\"\\nCalculating network features using {T} second time window...\")\n",
    "\n",
    "def calculate_features(df, T):\n",
    "    \"\"\"\n",
    "    Calculate fan-in and fan-out metrics for each flow within a sliding time window\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Input flows DataFrame\n",
    "    T (int): Time window in seconds\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Enriched DataFrame with fan-in/fan-out metrics\n",
    "    \"\"\"\n",
    "    # Convert period T to milliseconds\n",
    "    T_ms = T * 1000\n",
    "\n",
    "    # Initialize new columns for fan metrics\n",
    "    df['fan_out_src'] = 0  # Number of unique destinations from source\n",
    "    df['fan_in_dst'] = 0   # Number of unique sources to destination\n",
    "    df['fan_in_src'] = 0   # Number of unique sources to source\n",
    "    df['fan_out_dst'] = 0  # Number of unique destinations from destination\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating fan metrics\", unit=\"flows\"):\n",
    "        # Define sliding time window\n",
    "        mid_timestamp = row['bidirectional_first_seen_ms']\n",
    "        time_window_start = mid_timestamp - (T_ms // 2)\n",
    "        time_window_end = mid_timestamp + (T_ms // 2)\n",
    "\n",
    "        # Filter flows within time window\n",
    "        window_df = df[(df['bidirectional_first_seen_ms'] >= time_window_start) & \n",
    "                      (df['bidirectional_first_seen_ms'] <= time_window_end)].copy()\n",
    "\n",
    "        # Calculate fan metrics\n",
    "        df.at[i, 'fan_in_src'] = window_df[window_df['dst_ip'] == row['src_ip']]['src_ip'].nunique()\n",
    "        df.at[i, 'fan_out_src'] = window_df[window_df['src_ip'] == row['src_ip']]['dst_ip'].nunique()\n",
    "        df.at[i, 'fan_in_dst'] = window_df[window_df['dst_ip'] == row['dst_ip']]['src_ip'].nunique()\n",
    "        df.at[i, 'fan_out_dst'] = window_df[window_df['src_ip'] == row['dst_ip']]['dst_ip'].nunique()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the feature calculation function\n",
    "print(\"Calculating fan-in/fan-out metrics...\")\n",
    "df = calculate_features(flows_df, T)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched flows saved to csv_files/enriched_flows.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the enriched dataframe to a CSV file\n",
    "csv_filename = 'csv_files/enriched_flows.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"Enriched flows saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading ground truth data for flow labeling...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading ground truth data for flow labeling...\")\n",
    "# Load ground truth file for labeling\n",
    "gt_file = 'pcap_files/flows/TRAIN.gt'\n",
    "train_gt_df = pd.read_csv(gt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert necessary columns to compatible types\n",
    "df['src_port'] = df['src_port'].astype(int)\n",
    "df['dst_port'] = df['dst_port'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling flows based on ground truth data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling rows: 100%|██████████| 1029447/1029447 [07:37<00:00, 2252.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>application_name</th>\n",
       "      <th>bidirectional_packets</th>\n",
       "      <th>bidirectional_bytes</th>\n",
       "      <th>bidirectional_first_seen_ms</th>\n",
       "      <th>bidirectional_last_seen_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>bidirectional_stddev_piat_ms</th>\n",
       "      <th>src2dst_mean_piat_ms</th>\n",
       "      <th>src2dst_stddev_piat_ms</th>\n",
       "      <th>dst2src_mean_piat_ms</th>\n",
       "      <th>dst2src_stddev_piat_ms</th>\n",
       "      <th>fan_out_src</th>\n",
       "      <th>fan_in_dst</th>\n",
       "      <th>fan_in_src</th>\n",
       "      <th>fan_out_dst</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>3593</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>DNS</td>\n",
       "      <td>4</td>\n",
       "      <td>360</td>\n",
       "      <td>1421927414035</td>\n",
       "      <td>1421927414036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>33661</td>\n",
       "      <td>1024</td>\n",
       "      <td>17</td>\n",
       "      <td>NFS</td>\n",
       "      <td>8</td>\n",
       "      <td>960</td>\n",
       "      <td>1421927414236</td>\n",
       "      <td>1421927414272</td>\n",
       "      <td>...</td>\n",
       "      <td>6.890297</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.124356</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>12.701706</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.16</td>\n",
       "      <td>13284</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>20</td>\n",
       "      <td>1950</td>\n",
       "      <td>1421927413887</td>\n",
       "      <td>1421927416277</td>\n",
       "      <td>...</td>\n",
       "      <td>487.795105</td>\n",
       "      <td>183.538462</td>\n",
       "      <td>587.939001</td>\n",
       "      <td>474.200000</td>\n",
       "      <td>1053.091259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.6</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>1464</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>DNS</td>\n",
       "      <td>4</td>\n",
       "      <td>388</td>\n",
       "      <td>1421927414121</td>\n",
       "      <td>1421927414122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>32119</td>\n",
       "      <td>111</td>\n",
       "      <td>17</td>\n",
       "      <td>NFS</td>\n",
       "      <td>8</td>\n",
       "      <td>1008</td>\n",
       "      <td>1421927414221</td>\n",
       "      <td>1421927414299</td>\n",
       "      <td>...</td>\n",
       "      <td>21.388693</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>36.373067</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>42.146570</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         src_ip          dst_ip  src_port  dst_port  protocol  \\\n",
       "0    59.166.0.5   149.171.126.5      3593        53        17   \n",
       "1    59.166.0.0   149.171.126.9     33661      1024        17   \n",
       "2  175.45.176.0  149.171.126.16     13284        80         6   \n",
       "3    59.166.0.6   149.171.126.7      1464        53        17   \n",
       "4    59.166.0.0   149.171.126.9     32119       111        17   \n",
       "\n",
       "  application_name  bidirectional_packets  bidirectional_bytes  \\\n",
       "0              DNS                      4                  360   \n",
       "1              NFS                      8                  960   \n",
       "2             HTTP                     20                 1950   \n",
       "3              DNS                      4                  388   \n",
       "4              NFS                      8                 1008   \n",
       "\n",
       "   bidirectional_first_seen_ms  bidirectional_last_seen_ms  ...  \\\n",
       "0                1421927414035               1421927414036  ...   \n",
       "1                1421927414236               1421927414272  ...   \n",
       "2                1421927413887               1421927416277  ...   \n",
       "3                1421927414121               1421927414122  ...   \n",
       "4                1421927414221               1421927414299  ...   \n",
       "\n",
       "   bidirectional_stddev_piat_ms  src2dst_mean_piat_ms  src2dst_stddev_piat_ms  \\\n",
       "0                      0.577350              0.000000                0.000000   \n",
       "1                      6.890297              7.000000               12.124356   \n",
       "2                    487.795105            183.538462              587.939001   \n",
       "3                      0.577350              0.000000                0.000000   \n",
       "4                     21.388693             21.000000               36.373067   \n",
       "\n",
       "   dst2src_mean_piat_ms  dst2src_stddev_piat_ms  fan_out_src  fan_in_dst  \\\n",
       "0              0.000000                0.000000            6           7   \n",
       "1              7.333333               12.701706            7           8   \n",
       "2            474.200000             1053.091259            2           2   \n",
       "3              0.000000                0.000000            7           3   \n",
       "4             24.333333               42.146570            7           8   \n",
       "\n",
       "   fan_in_src  fan_out_dst  label  \n",
       "0           0            0      0  \n",
       "1           0            0      0  \n",
       "2           0            0      1  \n",
       "3           0            0      0  \n",
       "4           0            0      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_label(row):\n",
    "    \"\"\"\n",
    "    Match flow with ground truth data to determine if it's anomalous\n",
    "    Returns 1 for anomalous flows, 0 for normal flows\n",
    "    \"\"\"\n",
    "    # Match based on ports, protocol, and timestamp overlap\n",
    "    matched = train_gt_df[\n",
    "        (train_gt_df['src_port'] == row['src_port']) &\n",
    "        (train_gt_df['dst_port'] == row['dst_port']) &\n",
    "        (train_gt_df['protocol'] == row['protocol']) &\n",
    "        (train_gt_df['first_timestamp_ms'] <= row['bidirectional_last_seen_ms']) &\n",
    "        (train_gt_df['last_timestamp_ms'] >= row['bidirectional_first_seen_ms'])\n",
    "    ]\n",
    "    return 1 if not matched.empty else 0\n",
    "\n",
    "print(\"Labeling flows based on ground truth data...\")\n",
    "\n",
    "# Use tqdm to apply the function with a progress bar\n",
    "tqdm.pandas(desc=\"Labeling rows\")\n",
    "df['label'] = df.progress_apply(match_label, axis=1)\n",
    "\n",
    "# Display the first few rows of the labeled DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled flows saved to csv_files/raw_flows.csv\n"
     ]
    }
   ],
   "source": [
    "# Save labeled DataFrame\n",
    "df.to_csv('csv_files/labeled_flows.csv', index=False)\n",
    "print(f\"Labeled flows saved to labeled_flows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enriching data with IP classification...\n"
     ]
    }
   ],
   "source": [
    "def get_first_octet(ip):\n",
    "    \"\"\"Extract first octet from IP address\"\"\"\n",
    "    return int(ip.split('.')[0])\n",
    "\n",
    "def get_ip_class(ip):\n",
    "    \"\"\"\n",
    "    Determine IP address class based on first octet\n",
    "    Returns: Class A, B, C, D (multicast), or E (reserved)\n",
    "    \"\"\"\n",
    "    first_octet = get_first_octet(ip)\n",
    "    \n",
    "    if 0 <= first_octet <= 127:  # Class A\n",
    "        return 'Class A'\n",
    "    elif 128 <= first_octet <= 191:  # Class B\n",
    "        return 'Class B'\n",
    "    elif 192 <= first_octet <= 223:  # Class C\n",
    "        return 'Class C'\n",
    "    elif 224 <= first_octet <= 239:  # Class D (multicast)\n",
    "        return 'Class D (multicast)'\n",
    "    elif 240 <= first_octet <= 255:  # Class E (reserved)\n",
    "        return 'Class E (reserved)'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "print(\"\\nEnriching data with IP classification...\")\n",
    "# Apply IP classification\n",
    "df['src_ip_class'] = df['src_ip'].apply(get_ip_class)\n",
    "df['dst_ip_class'] = df['dst_ip'].apply(get_ip_class)\n",
    "df = pd.get_dummies(df, columns=['src_ip_class', 'dst_ip_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate flow duration\n",
    "df['bidirectional_duration_ms'] = df['bidirectional_last_seen_ms'] - df['bidirectional_first_seen_ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing numerical features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Standardizing numerical features...\")\n",
    "# Select numerical columns for standardization\n",
    "numeric_cols = ['bidirectional_bytes', 'bidirectional_duration_ms',\n",
    "       'bidirectional_mean_piat_ms', 'bidirectional_mean_ps',\n",
    "       'bidirectional_packets', 'bidirectional_stddev_piat_ms',\n",
    "       'bidirectional_stddev_ps', 'dst2src_mean_piat_ms', 'dst2src_mean_ps',\n",
    "       'dst2src_stddev_piat_ms', 'dst2src_stddev_ps', 'fan_in_dst',\n",
    "       'fan_in_src', 'fan_out_dst', 'fan_out_src', 'src2dst_mean_piat_ms',\n",
    "       'src2dst_mean_ps', 'src2dst_stddev_piat_ms', 'src2dst_stddev_ps']\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing protocol information...\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing protocol information...\")\n",
    "# Handle protocol encoding\n",
    "most_frequent_values = [6, 17, 89, 1, 132]  # Most common protocol numbers\n",
    "df['protocol'] = df['protocol'].where(df['protocol'].isin(most_frequent_values), 0)\n",
    "df = pd.get_dummies(df, columns=['protocol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing ports...\n"
     ]
    }
   ],
   "source": [
    "def get_port_cat(port):\n",
    "    \"\"\"\n",
    "    Categorize ports based on IANA assignments:\n",
    "    - Well-known ports: 0-1023\n",
    "    - Registered ports: 1024-49151\n",
    "    - Dynamic ports: 49152-65535\n",
    "    \"\"\"    \n",
    "    if 0 <= port <= 1023:\n",
    "        return 'WellKnown'\n",
    "    elif 1024 <= port <= 49151:\n",
    "        return 'Registered'\n",
    "    elif 49152 <= port <= 65535:\n",
    "        return 'Dynamic'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "print(\"Categorizing ports...\")\n",
    "# Apply port categorization\n",
    "df['src_port_class'] = df['src_port'].apply(get_port_cat)\n",
    "df['dst_port_class'] = df['dst_port'].apply(get_port_cat)\n",
    "df = pd.get_dummies(df, columns=['src_port_class', 'dst_port_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded DataFrame saved to csv_files/encoded_flows.csv\n"
     ]
    }
   ],
   "source": [
    "# Save encoded DataFrame\n",
    "csv_filename = 'csv_files/encoded_flows.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f'Encoded DataFrame saved to {csv_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating enriched feature DataFrame...\n",
      "Combining all feature sets...\n",
      "Creating connection pattern features...\n",
      "Creating timing features...\n",
      "Creating protocol features...\n",
      "Creating packet features...\n",
      "Creating behavioral features...\n"
     ]
    }
   ],
   "source": [
    "def create_connection_pattern_features(df):\n",
    "    \"\"\"\n",
    "    Create features based on connection patterns using fan-in/fan-out metrics\n",
    "    and IP class relationships\n",
    "    \"\"\"\n",
    "    print(\"Creating connection pattern features...\")\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Fan-in/fan-out ratios\n",
    "    features['fan_ratio_src'] = features['fan_out_src'] / (features['fan_in_src'] + 1e-6)\n",
    "    features['fan_ratio_dst'] = features['fan_out_dst'] / (features['fan_in_dst'] + 1e-6)\n",
    "    features['fan_total_src'] = features['fan_in_src'] + features['fan_out_src']\n",
    "    features['fan_total_dst'] = features['fan_in_dst'] + features['fan_out_dst']\n",
    "    \n",
    "    # Connectivity features\n",
    "    features['connection_asymmetry'] = np.abs(features['fan_total_src'] - features['fan_total_dst'])\n",
    "    features['connection_intensity'] = features['fan_total_src'] * features['fan_total_dst']\n",
    "    \n",
    "    # IP class-based features\n",
    "    features['ip_class_mismatch'] = (\n",
    "         (features['src_ip_class_Class A'] & features['dst_ip_class_Class C']) |\n",
    "         (features['src_ip_class_Class C'] & features['dst_ip_class_Class A'])\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Suspicious behavior detection based on IP classes\n",
    "    features['potential_broadcast_attack'] = (\n",
    "         features['dst_ip_class_Class D (multicast)'] & \n",
    "         (features['bidirectional_packets'] > features['bidirectional_packets'].quantile(0.95))\n",
    "    ).astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_timing_features(df):\n",
    "    \"\"\"\n",
    "    Create features based on timing characteristics\n",
    "    \"\"\"\n",
    "    print(\"Creating timing features...\")\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Timing ratios\n",
    "    features['piat_ratio_src2dst'] = features['src2dst_mean_piat_ms'] / (features['dst2src_mean_piat_ms'] + 1e-6)\n",
    "    features['piat_ratio_stddev'] = features['bidirectional_stddev_piat_ms'] / (features['bidirectional_mean_piat_ms'] + 1e-6)\n",
    "    \n",
    "    # Regularity features\n",
    "    features['timing_regularity'] = 1 - (features['bidirectional_stddev_piat_ms'] / \n",
    "                                         (features['bidirectional_mean_piat_ms'] + 1e-6))\n",
    "    \n",
    "    # Burst detection\n",
    "    features['burst_factor'] = (features['bidirectional_packets'] / \n",
    "                                (features['bidirectional_duration_ms'] + 1e-6))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_protocol_features(df):\n",
    "    \"\"\"\n",
    "    Create features based on protocols and ports\n",
    "    \"\"\"\n",
    "    print(\"Creating protocol features...\")\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Suspicious protocol/port combinations\n",
    "    features['suspicious_port_protocol'] = (\n",
    "         (features['protocol_17'] & features['dst_port_class_WellKnown'] & \n",
    "          (features['bidirectional_packets'] < features['bidirectional_packets'].quantile(0.1)))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Protocol anomalies\n",
    "    features['protocol_anomaly'] = (\n",
    "         (features['protocol_0'] | features['protocol_1'] | features['protocol_89'] | features['protocol_132'])\n",
    "    ).astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_packet_features(df):\n",
    "    \"\"\"\n",
    "    Create features based on packet characteristics\n",
    "    \"\"\"\n",
    "    print(\"Creating packet features...\")\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Packet size ratios\n",
    "    features['ps_ratio_src2dst'] = features['src2dst_mean_ps'] / (features['dst2src_mean_ps'] + 1e-6)\n",
    "    features['ps_variation_ratio'] = features['bidirectional_stddev_ps'] / (features['bidirectional_mean_ps'] + 1e-6)\n",
    "    \n",
    "    # Flow characteristics\n",
    "    features['flow_efficiency'] = features['bidirectional_bytes'] / (features['bidirectional_packets'] + 1e-6)\n",
    "    features['flow_regularity'] = 1 - (features['bidirectional_stddev_ps'] / (features['bidirectional_mean_ps'] + 1e-6))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_behavioral_features(df):\n",
    "    \"\"\"\n",
    "    Create features for detecting specific behaviors\n",
    "    \"\"\"\n",
    "    print(\"Creating behavioral features...\")\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Scan detection\n",
    "    features['potential_scan'] = (\n",
    "         (features['fan_out_dst'] > features['fan_out_dst'].quantile(0.95)) &\n",
    "         (features['bidirectional_packets'] < features['bidirectional_packets'].quantile(0.05)) &\n",
    "         (features['bidirectional_duration_ms'] < features['bidirectional_duration_ms'].quantile(0.05))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # DDoS detection\n",
    "    features['potential_ddos'] = (\n",
    "         (features['fan_in_dst'] > features['fan_in_dst'].quantile(0.95)) &\n",
    "         (features['bidirectional_packets'] > features['bidirectional_packets'].quantile(0.95)) &\n",
    "         (features['bidirectional_mean_piat_ms'] < features['bidirectional_mean_piat_ms'].quantile(0.05))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Data exfiltration detection\n",
    "    features['potential_exfiltration'] = (\n",
    "         (features['bidirectional_bytes'] > features['bidirectional_bytes'].quantile(0.95)) &\n",
    "         (features['dst2src_mean_ps'] < features['src2dst_mean_ps'] * 0.1)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_final_features(df):\n",
    "    \"\"\"\n",
    "    Combine all features into a single DataFrame\n",
    "    \"\"\"\n",
    "    print(\"Combining all feature sets...\")\n",
    "    connection_features = create_connection_pattern_features(df)\n",
    "    timing_features = create_timing_features(df)\n",
    "    protocol_features = create_protocol_features(df)\n",
    "    packet_features = create_packet_features(df)\n",
    "    behavioral_features = create_behavioral_features(df)\n",
    "    \n",
    "    final_features = pd.concat([\n",
    "         connection_features,\n",
    "         timing_features,\n",
    "         protocol_features,\n",
    "         packet_features,\n",
    "         behavioral_features\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    final_features = final_features.loc[:, ~final_features.columns.duplicated()]\n",
    "    \n",
    "    return final_features\n",
    "\n",
    "print(\"Generating enriched feature DataFrame...\")\n",
    "enriched_features_df = create_final_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame saved to csv_files/final_features_flows.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame with labels to a CSV file\n",
    "output_path = 'csv_files/final_features_flows.csv'\n",
    "enriched_features_df.to_csv(output_path, index=False)\n",
    "print(f\"Final DataFrame saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
